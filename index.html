<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Seong Joon Oh</title>
  
  <meta name="author" content="Seong Joon Oh">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="pictures/personal_round.png">
  
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-JKQK3E33B3"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-JKQK3E33B3');
  </script>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Seong Joon Oh</name>
              </p>
              <p>I am a research scientist at <a href="https://clova.ai/en/research/publications.html">NAVER AI Lab</a>, working on the challenges of deploying machine learning models in the real world.
                I am interested in training robust, probabilistic, and weakly-supervised models in pragmatic settings.
              </p>
              <p>
                I received my PhD in computer vision and machine learning at <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning">Max-Planck Institute for Informatics</a> in 2018, 
                under the supervision of <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele">Bernt Schiele</a> and <a href="https://cispa.saarland/group/fritz/">Mario Fritz</a>, 
                with a focus on the privacy and security implications of CV and ML (<a href="https://publikationen.sulb.uni-saarland.de/handle/20.500.11880/27146">Thesis</a>).
                I received the Master of Mathematics with <a href="https://en.wikipedia.org/wiki/Part_III_of_the_Mathematical_Tripos">Distinction</a> in 2014 and 
                Bachelor of Arts in Mathematics as a <a href="https://en.wikipedia.org/wiki/Wrangler_(University_of_Cambridge)">Wrangler</a> in 2013,
                both at University of Cambridge.
              </p>
              <p style="text-align:center">
                <a href="mailto:coallaoh@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=kmXOOdsAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/seong-joon-oh-32113479/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://twitter.com/coallaoh/">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/coallaoh/">Github</a>

              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="pictures/personal_round.png"><img style="width:80%;max-width:100%" alt="profile photo" src="pictures/personal_round.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I have tried to push certain fronts in ML research to make models truly useful and deployable in real life. They can be grouped into a few keywords.
                <br>
                <span style="background-color:#ff9aa2">Robustness</span>. 
                Changes in the input distribution shall not disrupt the model's predictive power. Ideally, a model should be robust against the shifts in input domain (<em>e.g.</em> natural and adversarial perturbations) and confounders (<em>e.g.</em> fairness). 
                <br>
                <span style="background-color:#ffdac1">Uncertainty</span>. 
                A model should know when it is going to get it wrong. This allows the users and downstream systems to make sensible and safe decisions based on the estimated confidence levels.
                <br>
                <span style="background-color:#ffffce">Weak Supervision</span>.
                Human supervision is often a bottleneck for training a model on a new task. I have sought cost-effective surrogates for the annotations and corresponding training methodologies.
                <br>
                <span style="background-color:#b5ead7">Privacy & Security</span>.
                There are different privacy and security angles with which ML can be analyzed. One may question the "stealability" of a black-box model as an IP; one may also question the privacy guarantees for user data in the federated learning setup. 
                Still others may wonder whether certain level privacy is achievable at all on internet, with the increasing volume of user data online and more widespread use of machine learning algorithms to process such data.
                <br>
                <span style="background-color:#c7ceea">Evaluation</span>.
                Correct evaluation is undoubtably important in research and industrial applications, yet it is surprisingly difficult. I have cleaned up benchmarks and evaluation protocols in a few domains.
                <br>
                <span style="background-color:#C9D3D8">Large-Scale ML</span>.
                Some of the methodologies I have been involved in are designed for large-scale ML. They typically require minimal changes to the original ML system but bring consistent gains across the board.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="pictures/choe2020cvpr.gif" alt="choe2020cvpr" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <span style="background-color:#ff9aa2">Robustness</span>
              <span style="background-color:#ffffce">Weak Supervision</span>
              <span style="background-color:#c7ceea">Evaluation</span>
              <br>
              <a href="data/choe2020arxiv.pdf">
                <papertitle>Evaluation for Weakly Supervised Object Localization: Protocol, Metrics, and Datasets
                </papertitle>
              </a>
              <br>
              <a href="https://sites.google.com/site/junsukchoe/">Junsuk Choe*</a>,
              <strong>Seong Joon Oh*</strong>,
              <a href="https://sanghyukchun.github.io/home/">Sanghyuk Chun</a>,
              <a href="https://eml-unitue.de/people/zeynep-akata">Zeynep Akata</a>,
              <a href="https://sites.google.com/site/katehyunjungshim/home">Hyunjung Shim</a>.
              <br>
              <em>*Equal contribution</em>
              <br>
              <em>arXiv</em>, 2020
              <br>
              <a href="data/choe2020arxiv">Bibtex</a> /
              <a href="https://github.com/clovaai/wsolevaluation">Code</a>
              <p>Journal extension of CVPR'20! It now contains more analyses, including the evaluation of input gradient variants as Weakly-Supervised Object Localization (WSOL) methods.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="pictures/heo2020arxiv.png" alt="heo2020arxiv" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <span style="background-color:#C9D3D8">Large-Scale ML</span>
              <br>
              <a href="data/heo2020adamp.pdf">
                <papertitle>Slowing Down the Weight Norm Increase in Momentum-Based Optimizers
                </papertitle>
              </a>
              <br>
              <a href="https://sites.google.com/view/byeongho-heo/home">Byeongho Heo*</a>,
              <a href="https://sanghyukchun.github.io/home/">Sanghyuk Chun*</a>,
              <strong>Seong Joon Oh</strong>,
              <a href="https://sites.google.com/site/dyhan0920/">Dongyoon Han</a>,
              <a href="https://sites.google.com/site/youngjunguh">Youngjung Uh</a>,
              <a href="https://sangdooyun.github.io/">Sangdoo Yun</a>,
              <a href="https://sites.google.com/site/hjw9096/">Jungwoo Ha</a>.
              <br>
              <em>*Equal contribution</em>
              <br>
              <em>arXiv</em>, 2020
              <br>
              <a href="data/heo2020adamp">Bibtex</a> /
              <a href="https://github.com/clovaai/AdamP">Code</a> /
              <a href="https://clovaai.github.io/AdamP/">Project</a>
              <p>When you apply a momentum-based optimizer over scale-invariant parameters, their norms increase quite a bit. 
                The norm increase doesn't contribute anything to the loss minimization while only slowing down the convergence.
                We fix this by appending a projection operation on SGD and Adam. This leads to performance improvements across the board. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="pictures/ferjad2020icml.png" alt="ferjad2020icml" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <span style="background-color:#c7ceea">Evaluation</span>
              <br>
              <a href="data/ferjad2020icml.pdf">
                <papertitle>Reliable Fidelity and Diversity Metrics for Generative Models
                </papertitle>
              </a>
              <br>
              <a href="https://sites.google.com/view/byeongho-heo/home">Muhammad Ferjad Naeem*</a>,
              <strong>Seong Joon Oh*</strong>,
              <a href="https://sites.google.com/site/youngjunguh">Youngjung Uh</a>,
              <a href="https://yunjey.github.io/">Yunjey Choi</a>,
              <a href="https://people.epfl.ch/jaejun.yoo/?lang=en">Jaejun Yoo</a>.
              <br>
              <em>*Equal contribution</em>
              <br>
              <em>ICML</em>, 2020
              <br>
              <a href="data/ferjad2020icml">Bibtex</a> /
              <a href="https://github.com/clovaai/generative-evaluation-prdc">Code</a> /
              <a href="https://www.youtube.com/watch?v=_XwsGkryVpk&feature=youtu.be&ab_channel=FerjadNaeem">Youtube</a>
              <p>Evaluating generative models is tricky. There are Inception Score and Fr&eacute;chet Inception Distance measures indeed, and then (Improved) Precision and Recall metrics to separately examine the fidelity and diversity aspects. 
              Yet, they are still not perfect. We address the issues with Improved Precision and Recall metrics and propose new metrics: Density and Coverage.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="pictures/bahng2020icml.png" alt="bahng2020icml" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <span style="background-color:#ff9aa2">Robustness</span>
              <span style="background-color:#ffffce">Weak Supervision</span>
              <span style="background-color:#c7ceea">Evaluation</span>
              <br>
              <a href="data/hyojin2020icml.pdf">
                <papertitle>Learning De-biased Representations with Biased Representations
                </papertitle>
              </a>
              <br>
              <a href="https://hjbahng.github.io/">Hyojin Bahng</a>,
              <a href="https://sanghyukchun.github.io/home/">Sanghyuk Chun</a>,
              <a href="https://sangdooyun.github.io/">Sangdoo Yun</a>,
              <a href="https://sangdooyun.github.io/">Jaegul Choo</a>,
              <strong>Seong Joon Oh</strong>.
              <br>
              <em>ICML</em>, 2020
              <br>
              <a href="data/hyojin2020icml">Bibtex</a> /
              <a href="https://github.com/clovaai/rebias">Code</a> /
              <a href="https://www.youtube.com/watch?v=lkjMxZDGubA">Youtube</a>
              <p>Models pick up correlations, rather than causal mechanisms, between inputs and outputs. 
              De-biasing (and fairness) researches have guided models on "which cues to look at" through explicit bias labels or by re-weighting or re-generating training data to remove bias.
              We show that, for many application scenarios, it is possible to encode the "cues to look at" through model architecture and such expensive strategies are no longer needed.  </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="pictures/choe2020cvpr.gif" alt="choe2020cvpr" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <span style="background-color:#ff9aa2">Robustness</span>
              <span style="background-color:#ffffce">Weak Supervision</span>
              <span style="background-color:#c7ceea">Evaluation</span>
              <br>
              <a href="data/choe2020cvpr.pdf">
                <papertitle>Evaluating Weakly-Supervised Object Localization Methods Right
                </papertitle>
              </a>
              <br>
              <a href="https://sites.google.com/site/junsukchoe/">Junsuk Choe*</a>,
              <strong>Seong Joon Oh*</strong>,
              <a href="https://sanghyukchun.github.io/home/">Sanghyuk Chun</a>,
              <a href="https://eml-unitue.de/people/zeynep-akata">Zeynep Akata</a>,
              <a href="https://sites.google.com/site/katehyunjungshim/home">Hyunjung Shim</a>.
              <br>
              <em>CVPR</em>, 2020
              <br>
              <a href="data/choe2020cvpr">Bibtex</a> /
              <a href="https://github.com/clovaai/wsolevaluation">Code</a>
              <p>I have long waited for this moment since CVPR'17. Weakly-Supervised Object Localization, or WSOL, has in fact been not weakly supervised in a strict sense.
              Design choices and hyperparameters are validated with the localization annotations! 
              This paper explains <em>why</em> researchers <em>had to</em> rely on localization validation -- without localization supervision, there is no way to force a model to not extract cues from background regions.
              We propose a new fair benchmark acknowledging the need for localization annotations and show that WSOL methods since CAM in 2016 have not introduced much gain.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="pictures/lee2020cvprw.png" alt="lee2020cvprw" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="data/lee2019arxiv.pdf">
                <papertitle>On Recognizing Texts of Arbitrary Shapes with 2D Self-Attention
                </papertitle>
              </a>
              <br>
              Junyeop Lee,
              <a href="https://sites.google.com/view/sungraepark">Sungrae Park</a>,
              <a href="http://jeonghunbaek.net/">Jeonghun Baek</a>,
              <strong>Seong Joon Oh</strong>,
              Seonghyeon Kim,
              <a href="https://github.com/hwalsuklee">Hwalsuk Lee</a>.
              <br>
              <em>CVPR Workshop</em>, 2020
              <br>
              <a href="data/lee2020selfattention">Bibtex</a>
              <p>Scene text recognition works well, but there are remaining corner cases. An example is texts with unusual orientations and arrangements (<em>e.g.</em> BMW logo).
              We focus on this corner case and propose a model based on self-attention. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="pictures/joon2015iccv.png" alt="joon2015iccv" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <span style="background-color:#b5ead7">Privacy & Security</span>
              <span style="background-color:#c7ceea">Evaluation</span>
              <br>
              <a href="data/oh2018tpami.pdf">
                <papertitle>Person Recognition in Personal Photo Collections
                </papertitle>
              </a>
              <br>
              <strong>Seong Joon Oh</strong>,
              <a href="http://rodrigob.github.io/">Rodrigo Benenson</a>,
              <a href="https://cispa.saarland/group/fritz/">Mario Fritz</a>,
              <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele">Bernt Schiele</a>.
              <br>
              <em>TPAMI</em>, 2020
              <br>
              <a href="data/joon2020tpami">Bibtex</a> /
              <a href="https://ieeexplore.ieee.org/document/8519337">Journal</a>
              <p>Journal version of my first paper ICCV'15, after five years! We have developed the version two of the ICCV'15 system that outperforms the methods that have appeared in the meantime.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="pictures/joon2018iclr.png" alt="joon2018iclr" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <span style="background-color:#b5ead7">Privacy & Security</span>
              <br>
              <a href="data/oh2018iclr.pdf">
                <papertitle>Towards Reverse-Engineering Black-Box Neural Networks
                </papertitle>
              </a>
              <br>
              <strong>Seong Joon Oh</strong>,
              <a href="https://cispa.saarland/group/fritz/">Mario Fritz</a>,
              <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele">Bernt Schiele</a>.
              <br>
              <em>Explainable AI: Interpreting, Explaining and Visualizing Deep Learning (book chapter)</em>, 2019
              <br>
              <a href="data/joon2019blackboxchapter">Bibtex</a> /
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-28954-6_7">Book chapter</a>
              <p>Book chapter version of ICLR'18! We build connections between our black-box inspection methodology and the explainable AI.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="pictures/orekondy2019neuripsfl.png" alt="orekondy2019neuripsfl" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <span style="background-color:#b5ead7">Privacy & Security</span>
              <br>
              <a href="data/orekondy2019neuripsfl.pdf">
                <papertitle>Gradient-Leaks: Understanding and Controlling Deanonymization in Federated Learning
                </papertitle>
              </a>
              <br>
              <a href="https://tribhuvanesh.github.io/">Tribhuvanesh Orekondy</a>,
              <strong>Seong Joon Oh</strong>,
              <a href="https://yangzhangalmo.github.io/">Yang Zhang</a>,
              <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele">Bernt Schiele</a>,
              <a href="https://cispa.saarland/group/fritz/">Mario Fritz</a>.
              <br>
              <em>NeurIPS Workshop</em>, 2019
              <br>
              <a href="data/orekondy19neuripsfl">Bibtex</a> /
              <a href="data/orekondy2019neuripsfl_poster.pdf">Poster</a>
              <p>Federated learning allows sensitive user data to never leave the device and still be used for training. It is considered a safer option than sending the user data directly to the server.
              But is it? We show that users may be identified and linked based on the model updates communicated between the device and server.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="pictures/chun2019icmlw.png" alt="chun2019icmlw" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <span style="background-color:#ff9aa2">Robustness</span>
              <span style="background-color:#ffdac1">Uncertainty</span>
              <span style="background-color:#c7ceea">Evaluation</span>
              <br>
              <a href="data/chun2019icmlw.pdf">
                <papertitle>An Empirical Evaluation on Robustness and Uncertainty of Regularization Methods
                </papertitle>
              </a>
              <br>
              <a href="https://sanghyukchun.github.io/home/">Sanghyuk Chun</a>,
              <strong>Seong Joon Oh</strong>,
              <a href="https://sangdooyun.github.io/">Sangdoo Yun</a>,
              <a href="https://sites.google.com/site/dyhan0920/">Dongyoon Han</a>,
              <a href="https://sites.google.com/site/junsukchoe/">Junsuk Choe</a>,
              <a href="https://yjyoo3312.github.io/">Youngjoon Yoo</a>.
              <br>
              <em>ICML Workshop</em>, 2019
              <br>
              <a href="data/chun2019icmlw">Bibtex</a>
              <p>There has been a line of research on simple regularization techniques like CutMix (ICCV'19) and other lines of research on robustness and uncertainty.
              We make a happy marriage of the two and measure how well the regularization techniques improve robustness and uncertainty of a model.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="pictures/yun2019iccv.png" alt="yun2019iccv" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <span style="background-color:#ff9aa2">Robustness</span>
              <span style="background-color:#C9D3D8">Large-Scale ML</span>
              <br>
              <a href="data/yun2019iccv.pdf">
                <papertitle>CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features
                </papertitle>
              </a>
              <br>
              <a href="https://sangdooyun.github.io/">Sangdoo Yun</a>,
              <a href="https://sites.google.com/site/dyhan0920/">Dongyoon Han</a>,
              <strong>Seong Joon Oh</strong>,
              <a href="https://sanghyukchun.github.io/home/">Sanghyuk Chun</a>,
              <a href="https://sites.google.com/site/junsukchoe/">Junsuk Choe</a>,
              <a href="https://yjyoo3312.github.io/">Youngjoon Yoo</a>.
              <br>
              <em>ICCV Oral Talk</em>, 2019
              <br>
              <a href="data/yun2019cutmix">Bibtex</a> /
              <a href="https://github.com/clovaai/CutMix-PyTorch">Code</a> /
              <a href="data/yun2019iccv_talk.pdf">Talk</a> /
              <a href="data/yun2019iccv_poster.pdf">Poster</a> /
              <a href="https://clova-ai.blog/2019/07/15/cutmix-regularization-strategy-to-train-strong-classifiers-with-localizable-features/">Blog</a> /
              <a href="https://clovaai.github.io/AdamP/">Project</a> /
              <a href="https://clovaai.github.io/AdamP/">Project</a>
              <p>A simple solution that works surprisingly well! Cut and paste patches from other images during training. Quite likely, you will see a performance boost.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="pictures/baek2019iccv.png" alt="baek2019iccv" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <span style="background-color:#c7ceea">Evaluation</span>
              <br>
              <a href="data/baek2019iccv.pdf">
                <papertitle>What Is Wrong with Scene Text Recognition Model Comparisons? Dataset and Model Analysis
                </papertitle>
              </a>
              <br>
              <a href="http://jeonghunbaek.net/">Jeonghun Baek</a>,
              <a href="http://geewook.kim/">Geewook Kim</a>,
              Junyeop Lee,
              <a href="https://sites.google.com/view/sungraepark">Sungrae Park</a>,
              <a href="https://sites.google.com/site/dyhan0920/">Dongyoon Han</a>,
              <a href="https://sangdooyun.github.io/">Sangdoo Yun</a>,
              <strong>Seong Joon Oh</strong>,
              <a href="https://github.com/hwalsuklee">Hwalsuk Lee</a>.
              <br>
              <em>ICCV Oral Talk</em>, 2019
              <br>
              <a href="data/baek2019STRcomparisons">Bibtex</a> /
              <a href="https://github.com/clovaai/deep-text-recognition-benchmark">Code</a>
              <p>Scene text recognition field has long suffered from the lack of a unified agreement on the evaluation protocol.
              We provide a standard protocol. We also provide a unified view on the previous methods and discover a novel combination of existing modules that turns out to be the state of the art.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="pictures/joon2019iclr.png" alt="joon2019iclr" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <span style="background-color:#ffdac1">Uncertainty</span>
              <br>
              <a href="data/oh2019iclr.pdf">
                <papertitle>Modeling Uncertainty with Hedged Instance Embedding
                </papertitle>
              </a>
              <br>
              <strong>Seong Joon Oh</strong>,
              <a href="https://research.google/people/KevinMurphy/">Kevin Murphy</a>,
              Jiyan Pan,
              <a href="https://research.google/people/JosephRoth/">Joseph Roth</a>,
              <a href="https://www.florian-schroff.de/">Florian Schroff</a>,
              <a href="https://research.google/people/AndrewGallagher/">Andrew Gallagher</a>.
              <br>
              <em>ICLR</em>, 2019
              <br>
              <a href="data/joon2019iclr">Bibtex</a> /
              <a href="data/oh2019iclr_poster.pdf">Poster</a>
              <p>There has been quite some work on representing uncertainty for classification or regression tasks.
              Is there a way to represent uncertainty for instance embedding models too?
              We show that it is possible to train probabilistic representatitons for instances based on their inherent ambiguity.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="pictures/tretschk2018cscs.png" alt="tretschk2018cscs" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <span style="background-color:#b5ead7">Privacy & Security</span>
              <br>
              <a href="data/tretschk2018cscs.pdf">
                <papertitle>Sequential Attacks on Agents for Long-Term Adversarial Goals
                </papertitle>
              </a>
              <br>
              <a href="https://tribhuvanesh.github.io/">Edgar Tretschk</a>,
              <strong>Seong Joon Oh</strong>,
              <a href="https://cispa.saarland/group/fritz/">Mario Fritz</a>.
              <br>
              <em>ACM CSCS</em>, 2018
              <br>
              <a href="data/edgar2018cscs">Bibtex</a>
              <p>Can a bad guy hijack an RL agent? We show that it is possible to let an agent pursue an alternative reward by introducing small adversarial perturbations in the input stream.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="pictures/joon2018iclr.png" alt="joon2018iclr" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <span style="background-color:#b5ead7">Privacy & Security</span>
              <br>
              <a href="data/oh2018iclr.pdf">
                <papertitle>Towards Reverse-Engineering Black-Box Neural Networks
                </papertitle>
              </a>
              <br>
              <strong>Seong Joon Oh</strong>,
              Max Augustin,
              <a href="https://cispa.saarland/group/fritz/">Mario Fritz</a>,
              <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele">Bernt Schiele</a>.
              <br>
              <em>ICLR</em>, 2018
              <br>
              <a href="data/joon2018iclr">Bibtex</a> /
              <a href="data/oh2018iclr_abstract.pdf">Extended abstract</a> /
              <a href="data/oh2018iclr_poster.pdf">Poster</a> /
              <a href="https://github.com/coallaoh/WhitenBlackBox">Code</a>
              <p>Recipes for training a high-performance model are not cheap. Think about the GPU-and-research-scientist-and-engineer hours to find the right architectural components and optimizer hyperparameters.
              What if they can be stolen by examining the model responses to certain inputs? </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="pictures/sun2017cvpr.png" alt="sun2017cvpr" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <span style="background-color:#b5ead7">Privacy & Security</span>
              <br>
              <a href="data/sun2018cvpr.pdf">
                <papertitle>Natural and Effective Obfuscation by Head Inpainting
                </papertitle>
              </a>
              <br>
              <a href="https://qianrusun.com/">Qianru Sun</a>,
              <a href="http://charliememory.github.io/">Liqian Ma</a>,
              <strong>Seong Joon Oh</strong>,
              <a href="https://ee.ethz.ch/the-department/faculty/professors/person-detail.OTAyMzM=.TGlzdC80MTEsMTA1ODA0MjU5.html">Luc Van Gool</a>,
              <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele">Bernt Schiele</a>,
              <a href="https://cispa.saarland/group/fritz/">Mario Fritz</a>.
              <br>
              <em>CVPR</em>, 2018
              <br>
              <a href="data/qianru2018cvpr">Bibtex</a>
              <p>Adversarial perturbation solutions (ICCV'17) produce visually pleasant protections with high protection rates, but their effects may be confined to a handful of recognition systems.
              We propose another solution based on face inpainting that changes the face to a fictitious yet natural-looking identity. It is effective against a broader set of recognition systems. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="pictures/joon2017cvprw.png" alt="joon2017cvprw" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <span style="background-color:#b5ead7">Privacy & Security</span>
              <br>
              <a href="data/oh2017cvprw.pdf">
                <papertitle>From Understanding to Controlling Privacy against Automatic Person Recognition in Social Media
                </papertitle>
              </a>
              <br>
              <strong>Seong Joon Oh</strong>,
              <a href="https://cispa.saarland/group/fritz/">Mario Fritz</a>,
              <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele">Bernt Schiele</a>.
              <br>
              <em>CVPR Workshop</em>, 2017
              <br>
              <a href="data/joon2017cvprw">Bibtex</a> /
              <a href="data/oh2017cvprw_poster.pdf">Poster</a>
              <p>We stop and look back on the visual privacy papers (ICCV'15, ECCV'16, ICCV'17).</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="pictures/joon2017iccv.png" alt="joon2017iccv" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <span style="background-color:#ff9aa2">Robustness</span>
              <span style="background-color:#b5ead7">Privacy & Security</span>
              <span style="background-color:#c7ceea">Evaluation</span>
              <br>
              <a href="data/oh2017iccv.pdf">
                <papertitle>Adversarial Image Perturbation for Privacy Protection -- A Game Theory Perspective
                </papertitle>
              </a>
              <br>
              <strong>Seong Joon Oh</strong>,
              <a href="https://cispa.saarland/group/fritz/">Mario Fritz</a>,
              <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele">Bernt Schiele</a>.
              <br>
              <em>ICCV</em>, 2017
              <br>
              <a href="data/joon2017iccv">Bibtex</a> /
              <a href="data/oh2017iccv_poster.pdf">Poster</a> /
              <a href="https://github.com/coallaoh/AIP">Code</a>
              <p>If face blurring doesn't work (ECCV'16), how should we shield our personal photos online against recognition systems? 
                We propose a solution based on adversarial perturbations and the game theoretic considerations for the evaluation therein.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="pictures/joon2017cvpr.png" alt="joon2017cvpr" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <span style="background-color:#ffffce">Weak Supervision</span>
              <br>
              <a href="data/oh2017cvpr.pdf">
                <papertitle>Exploiting Saliency for Object Segmentation from Image Level Labels
                </papertitle>
              </a>
              <br>
              <strong>Seong Joon Oh</strong>,
              <a href="http://rodrigob.github.io/">Rodrigo Benenson</a>,
              <a href="https://www.linkedin.com/in/anna-khoreva/">Anna Khoreva</a>,
              <a href="https://eml-unitue.de/people/zeynep-akata">Zeynep Akata</a>,
              <a href="https://cispa.saarland/group/fritz/">Mario Fritz</a>,
              <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele">Bernt Schiele</a>.
              <br>
              <em>CVPR</em>, 2017
              <br>
              <a href="data/joon2017cvpr">Bibtex</a> /
              <a href="data/oh2017cvpr_poster.pdf">Poster</a> /
              <a href="https://github.com/coallaoh/GuidedLabelling">Code</a>
              <p>There has been quite some work around training models for localization tasks (<em>e.g.</em> semantic segmentation) from the image tag supervision only.
                But is this fundamentally possible without relying on extensive validation with full localization annotations? 
                We argue that certain priors are necessary at the very least to encode the extent of objects. Saliency, we argue, is a handy prior.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="pictures/anja2017cvpr.png" alt="anja2017cvpr" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="data/rohrbach2017cvpr.pdf">
                <papertitle>Generating Descriptions with Grounded and Co-Referenced People
                </papertitle>
              </a>
              <br>
              <a href="https://anna-rohrbach.net/">Anna Rohrbach</a>,
              <a href="https://rohrbach.vision/">Marcus Rohrbach</a>,
              <a href="https://inf.ethz.ch/people/person-detail.MjYyNzgw.TGlzdC8zMDQsLTg3NDc3NjI0MQ==.html">Siyu Tang</a>,
              <strong>Seong Joon Oh</strong>,
              <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele">Bernt Schiele</a>.
              <br>
              <em>CVPR</em>, 2017
              <br>
              <a href="data/anja2017cvpr">Bibtex</a>
              <p>We casually use pronouns to refer to others. For machines, however, referring to people with pronouns necessitates new types of data and training strategies to explicitly localize and link people across frames. We do that. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="pictures/joon2016eccv.png" alt="joon2016eccv" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <span style="background-color:#b5ead7">Privacy & Security</span>
              <span style="background-color:#c7ceea">Evaluation</span>
              <br>
              <a href="data/oh2016eccv.pdf">
                <papertitle>Faceless Person Recognition; Privacy Implications in Social Media
                </papertitle>
              </a>
              <br>
              <strong>Seong Joon Oh</strong>,
              <a href="http://rodrigob.github.io/">Rodrigo Benenson</a>,
              <a href="https://cispa.saarland/group/fritz/">Mario Fritz</a>,
              <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele">Bernt Schiele</a>.
              <br>
              <em>ECCV</em>, 2016
              <br>
              <a href="data/joon2016eccv">Bibtex</a> /
              <a href="data/oh2016eccv_poster.pdf">Poster</a> /
              <a href="data/oh2016eccvw.pdf">Extended abstract</a>
              <p>But can you still be recognized even with a blur on your face? Quite likely.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="pictures/aditya2016mobisys.png" alt="aditya2016mobisys" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <span style="background-color:#b5ead7">Privacy & Security</span>
              <br>
              <a href="data/aditya2016mobisys.pdf">
                <papertitle>I-pic: A Platform for Privacy-Compliant Image Capture
                </papertitle>
              </a>
              <br>
              <a href="https://www.bell-labs.com/usr/paarijaat.aditya">Paarijaat Aditya</a>,
              <a href="http://www.cse.iitd.ernet.in/~rijurekha/">Rijurekha Sen</a>,
              <a href="https://people.mpi-sws.org/~druschel/">Peter Druschel</a>,
              <strong>Seong Joon Oh</strong>,
              <a href="http://rodrigob.github.io/">Rodrigo Benenson</a>,
              <a href="https://cispa.saarland/group/fritz/">Mario Fritz</a>,
              <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele">Bernt Schiele</a>,
              <a href="https://www.cs.umd.edu/people/bobby">Bobby Bhattacharjee</a>,
              <a href="https://www.urmc.rochester.edu/biostat/people/faculty/wu-tongtong.aspx"> Tong Tong Wu</a>.
              <br>
              <em>MobiSys</em>, 2016
              <br>
              <a href="data/aditya2016mobisys">Bibtex</a> /
              <a href="http://ipic.mpi-sws.org/">Project</a>
              <p>You are a janitor at Taj Mahal. Against you will, sightseers take photos with your face in the background. How can you opt out of being present in someone else's photo? We present a mobile-system based solution.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="pictures/joon2015iccv.png" alt="joon2015iccv" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <span style="background-color:#b5ead7">Privacy & Security</span>
              <span style="background-color:#c7ceea">Evaluation</span>
              <br>
              <a href="data/oh2015iccv.pdf">
                <papertitle>Person Recognition in Personal Photo Collections
                </papertitle>
              </a>
              <br>
              <strong>Seong Joon Oh</strong>,
              <a href="http://rodrigob.github.io/">Rodrigo Benenson</a>,
              <a href="https://cispa.saarland/group/fritz/">Mario Fritz</a>,
              <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele">Bernt Schiele</a>.
              <br>
              <em>ICCV</em>, 2015
              <br>
              <a href="data/joon2015iccv">Bibtex</a> /
              <a href="data/oh2015iccv_poster.pdf">Poster</a> /
              <a href="https://www.youtube.com/watch?v=F4Jh0f3xD0g">Video</a> /
              <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/people-detection-pose-estimation-and-tracking/person-recognition-in-personal-photo-collections/">Project</a>
              <p>How well does a CNN model recognize people in personal photos? Even when people don't look at cameras, CNN finds out who they are, based on the context (<em>e.g.</em> location and social connections).</p>
            </td>
          </tr>

        </tbody></table>

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Template based on <a href="https://jonbarron.info/">Jon Barron's website</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
